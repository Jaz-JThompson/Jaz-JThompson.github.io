---
title: 'A Review: A Long Short-Term Memory Network for Plasma Diagnosis from Langmuir Probe Data'
date: 2022-11-03
permalink: /posts/2022/11/LSTM-NN-Langmuir/
layout: single
tags:
  - Fusion Plasma
  - Langmuir Probes
  - Machine Learning
toc: true
toclabel: "My Table of Contents"
tocicon: "cog"
toc_stickey: true
---

# Introduction

Welcome to my latest blog post where we will be discussing the recent paper "A Long Short-Term Memory Network for Plasma Diagnosis from Langmuir Probe Data", found [Here](https://www.mdpi.com/1424-8220/22/11/4281 "A Long Short-Term Memory Network for Plasma Diagnosis from Langmuir Probe Data"). This paper, published in the Journal of Nuclear Materials and Energy, presents a new approach to diagnosing plasma using a Long Short-Term Memory (LSTM) network. As fusion physicists, I am always excited to see new techniques and ideas being applied to the field of plasma physics. In this post, I will provide an overview of the paper, explain what an LSTM network is and how it works, and give some thoughts on the potential impact of this research on the fusion field. So, let's dive in!

## Fusion plasmas… why are they important?

The development of fusion plasma devices has rapidly increased in the last 20 years, bringing us ever closer to green, sustainable energy. Plasmas as the fourth state of matter where ions and electrons are unbound and move freely from one another at high temperatures. These high temperatures and pressures maintained by various heating techniques and supercooled magnets cause nuclei to fuse, generating massive amounts of energy. However, maintaining a fusion plasma is no easy task. 
Safe ignition, maintenance and dispersion of plasma discharges are heavily reliant on the capabilities of the diagnostic sensors. As the majority of small to medium sized reactors only produce plasmas for 0.001-1 second, diagnostics must be fast, responsive and accurate to provide live feedback control or accurate post-plasma diagnostics. Plasma parameters such as electron temperature, density and potential are calculated from data collected by these diagnostic sensors. These parameters can then be used to determine the form of the plasma, weather the plasma is stable or tending to instability e.t.c..  

Conventional diagnostic techniques for extracting the plasma parameters, such as the Langmuir probe, involve active and indirect measure of the plasma. In this case, the plasma is changed in a small area by the diagnostic to probe to obtain the characteristics from it. However, these types of measurement usually require a certain amount of offline-computation, hence cannot be used as live diagnostic tools. Additionally, external factors can greatly affect the accuracy of the plasma measurements.
In this paper aims to create a more universal method of plasma diagnosis by speeding up parameter calculation and eliminating the influence of external factors using long short-term memory (LSTM) neural networks (NN). 

<a id="Langmuir_math"></a>
## The Langmuir probe and how it works
Langmuir probes, proposed in 1926, are a commonly used diagnostic tool in plasma physics research. They essentially work by inserting a small probe into the plasma and measuring the electrical characteristics of the plasma at that point. The probe has a small wire or needle that is oscillated between being positively and negatively charged, which is inserted into the plasma. The electrons in the plasma are attracted to the positively charged probe and flow toward it, creating an electric current. By measuring the current as a function of the voltage applied to the probe, we can deduce important properties of the plasma from the I-V characteristics, such as the electron temperature, $T_e$ and density, $n_e$. One of the great things about Langmuir probes is that they can be used to make measurements in a wide range of plasmas, from fusion plasmas to the plasma in stars. They are a simple yet powerful tool that can provide a lot of information about the plasma being studied [[1]](https://aapt.scitation.org/doi/10.1119/1.2772282 "Understanding Langmuir probe current-voltage characteristics").

<div style="text-align:center">
    <a href="https://davidpace.com/example-of-langmuir-probe-analysis/">
        <img src="/images/Langmuir_Setup.png" alt="Langmuir_Setup" style="width:70%;height:50%">
    </a>
    <br>
    <i>Figure 1: Circuit diagram of the Langmuir probe setup</i>
</div>

The aim of the paper is to determine the characteristics $n_e$ and $T_e$. These are found using theoretical models based of a perfect plasma and fitting them to the data obtained from the probe. The perfect data curve from a Langmuir probe would look a little like an 'S' like that in [fig. 2](#CharsIV). For those interested in how Langmuir's method finds the characteristics, we go into a little more mathematical detail here, otherwise feel free to skip to the next section [Problems with measurements](#Problems-with-measurements).

I-V characteristic is obtained by sweeping a bias voltage (VB) from negative to positive potentials. From these curves the plasma characteristics are calculated from specific features of the curve:

<div style="text-align:center" id="CharsIV">
    <a href="https://aapt.scitation.org/doi/10.1119/1.2772282">
        <img src="/images/Langmuir_chars.png" alt="Langmuir_chars" style="width:100%;height:100%">
    </a>
    <br>
    <i>Figure 2: Langmuir probe I-V characteristic</i>
</div>

The total current in [fig. 2](#CharsIV) is represented by the black curve and the ionic and electron current are represented by the blue and red curves respectively. Different features of the black I-V characteristic are used to find $n_e$ and $T_e$:
  * Floating potential, $V_f$: The point where the total voltage of the probe changes sign
  * Plasma potential, $V_p$: The point where the curve bends to the right (i.e. Where all the electrons are repelled)
  * Electron temperature, $T_e$: The gradient of the middle region labeled in blue on [fig. 2](#CharsIV) is $=e/{(k_bT_e)}$

Knowing all these values allows us to apply the following relations to determine $n_e$ using,

$$ I_{sat} = A_se^{-\frac{1}{2}}qn_e\sqrt{\frac{K_BT_e}{M}} $$

$$ n_e = \frac{I_{sat} }{qA_se^{-\frac{1}{2}}}\sqrt{\frac{M}{K_BT_e}} $$

Where the new terms here are ion mass, $M$, area of the probe, $A_s$ and the physical constants, $K_B$ = Boltzmann's Constant and $e$ = electric charge.

These Characteristics are obtained post-processing and curve fitting of the data collected during experimentation. These relations are purely based on theory, and change depending on the probe geometry, conductivity, plasma type, e.t.c... 

<a id="Problems-with-measurements"></a>
## Problems with measurements
 Theoretical models are seldom perfect and the case of Langmuir probes is no different. The I-V characteristic drastically deviates from the standard from if the surface layer of the probe is contaminated or if the probe is placed in a low-density plasma. The characteristic bends in the curve are no longer as obvious, and as the voltage sweeps from negative to positive, the curves no longer overlap. This can make the gradient value very hard to find. A bad curve example can be seen in [fig. 3](#cont_probe). 

<div style="text-align:center" id = "cont_probe">
    <a href="https://www.mdpi.com/1424-8220/22/11/4281">
        <img src="/images/contaminated.png" alt="Langmuir_contam" style="width:60%;height:60%">
    </a>
    <br>
    <i>Figure 3: A contaminated probe's I-V characteristic</i>
</div>

Faced with these issues, traditional fitting methods can be even more of a challenge. Different levels of contamination and low data acquisition of low-density plasmas leads to a lot of noise in the data. This requires a lot of computational resources and can be very slow, which isn't ideal when you're trying to analyze data in real-time. So, the goal of this research was to develop a new method for diagnosing plasmas using Langmuir probe data that is faster, more accurate and doesn't suffer from the problem of probe contamination and low-density plasmas. And, it looks like they succeeded!


<div style="text-align:center">
            <img src="/images/NN_structure_graphic.png" alt="NN_graphic" style="width:100%;height:80%">
    <br>
    <i>Figure 4: The Researchers goal for the input and output of their network</i>
</div>

# Machine Learning 
Predicting $n_e$ and $T_e$ is a simple regression problem and can be resolved with a simple multi-layer perceptron (MLP) network. These MLP networks are relatively easy to use and lightweight, but not suited to characterize messy data that could be affected by multiple factors of varying degrees (such as the level of contamination). Hence, instead of using one-way propagation system in the MLP, they use a neural network structure called long short-term memory network (LSTM). 

<a id="LSTM"></a>
## LSTM , what is it and how does it work?
Now hopefully, when I mention Langmuir probes again, you have a general idea of what I’m talking about. This is because we don’t start thinking from scratch. All because we have moved on to the next section, doesn’t mean we forget everything from before. As you read the blog, you understand the context of each section based on the previous sections. You don’t throw away all your knowledge and start thinking from scratch again. There is a certain continuity to our thoughts. 

However,  traditional neural networks can’t do this. Regular neural networks have a hard time understanding sequences of data. They're good at recognizing patterns in a single data point, like identifying a picture of a cat... as a picture of a cat. But when it comes to understanding something like a sentence or a time series, regular neural networks can struggle. Sequential networks struggle relating previous words in a sentence with the next ones, essentially, forgetting everything every time new information given. Recurrent neural networks (RNN) attempt to solve this by having loops within the network, allowing them to persist. RNNs can be thought of as multiple copies of the same traditional sequential network but every time it runs, information is carried over to the successor. 

Because of RNN’s ability to remember past information, they have been incredibly successful when applied to tasks such as translation, text generation, speech recognition… and many more. 

However, RNNs have some fatal flaws and may not be completely suitable for prediction based on information given quite a while ago. This was explored in detail by  [Hochreiter](https://people.idsia.ch/~juergen/SeppHochreiter1991ThesisAdvisorSchmidhuber.pdf "Untersuchungen zu dynamischen neuronalen Netzen"), who proved   mathematically to why this is difficult. 

That's where LSTMs come in. LSTMS are a special kind of RNN used for any series where a sequential prediction is required, and long-term dependency is attached to it. Like all neural networks, there are repeating cell with hidden layers (e.g. activation function)  side. The LSTM cell looks like this: 

<div style="text-align:center">
            <img src="/images/cell(2).png" alt="LSTM_cell" style="width:80%;height:80%">
    <br>
</div>
<div style="text-align:center">
            <img src="/images/operations.png" alt="LSTM_operators" style="width:80%;height:80%">
    <br>
    <i>Figure 5: A general structure for an LSTM cell</i>
</div>

The diagram above illustrates how information flows through an LSTM network. Each line represents a vector that connects the output of one node, to the input of others. The pink circles represent simple operations like adding vectors together, while the yellow boxes represent layers of the neural network. When lines come together, it means the vectors are being combined, and when a line splits, it means the information is being copied and sent to different parts of the network.

To understand exactly what an LSTM cell is doing with the data, lets break it down into 4 parts.

<div style="text-align:center" id="LSTM_cell">
            <img src="/images/cell_breakdown_2x2.png" alt="LSTM_operators" style="width:100%;height:100%">
    <br>
    <i>Figure 6: A breakdown of an LSTM cell</i>
</div>

The memory part of the LSTM cell is the cell state vector. Information is added or removed to the cell state via the interactions with the gates. Gates consist of two parts: a sigmoid neural network layer and a point-wise multiplication operation. The sigmoid layer is used to decide how much information should be kept or discarded (by assigning a value between 0-1), and the point-wise multiplication operation add this information to the cell state.

<div style="text-align:center" id="cell_state">
            <img src="/images/cell_state_vec.png" alt="alt text" width="80%" height="80%">
    <br>
</div>


The first gate controls how much information we want to remove from the cell state, hence aptly named the 'forget gate'. It takes the output value $h_{t-1}$ from the previous cell and the new data point $x_t$ and decides how much information from the previous cell is relevant. Combining that with the trainable weights, $W$ and biases $b$ of that layer results in $f_t$ being passed onto the cell state vector. $f_t$ is multiplied by the old cell state, $C_{t-1}$ hence the cell forgets what it has decided to forget and is passed onto the next gate.

<div style="text-align:center" id="forgetGate">
            <img src="/images/Slide4.JPG" alt="alt text" width="100%" height="100%">
    <br>
</div>

Now its time do decide which information from the new data is doing to be passed on to the cell state. This is determined by the 'input gate'. The sigmoid layer chooses what to keep and what needs updating and the tanh layer creates a vector of suggested new values for the update, $C_t'$. Now that we have what needs replacing and what we could be replaced with, again, we update the old cell state, $C_{t-1}$ by $i_t \times C'_t$ to the new cell state $C_t$. This updates the chosen cell haves from the sigmoid layer. 
<div style="text-align:center" id="input">
            <img src="/images/Slide5.JPG" alt="alt text" width="100%" height="100%">
    <br>
</div>

Finally, we decide what we want to output from the cell, determined by the output gate. The output gate combines the cell input $h_{t-1}$ with a modified copy of the new cell state $C_t$. This means only the important parts of the cell state and previous cell are kept and passed on as the new input to the next cell, $h_t$.This output, $h_t$ is then copied and outputted at $y_t$.

<div style="text-align:center" id="output">
            <img src="/images/Slide6.JPG" alt="alt text" width="100%" height="100%">
    <br>
</div>

These cells can be strung together and are great for time-dependant data and memory tasks. Now we have a better idea of whats going on in the cell, we can look at how the paper applies LSTM networks to the Langmuir probe data.

If you're interested in how LSTMs work in detail and want to know how different types work, I would recommend reading [colah's blog](https://colah.github.io/posts/2015-08-Understanding-LSTMs/).
{: .notice}

# Experimental setup

## Collecting data

In this experiment, we'll be looking at the effects of humidity on two identical Langmuir probes - one labeled "Pcont" and the other "Pclean." First, we'll leave both probes exposed to a humid atmosphere for more than 24 hours, thus 'contaminating' them. Next, we'll place both probes on a special platform in a plasma vacuum chamber and mark their positions. They are placed the same distance away from the plasma course, so that they will detect the same plasma conditions. 

Then, we'll heat up a filament and fill the chamber with argon gas to create a steady plasma discharge. We'll apply a negative 200V to the Pclean probe for ten minutes to remove any contaminated layer on the probe's surface by heating it and using electrons to bombard it.

 After that, we'll use the platform to move both probes to a central position and collect data on their current and voltage (I-V) characteristics. We'll make sure to collect data on both probes within a one-minute time frame.

Finally, we'll analyze the collected data using both traditional diagnostic methods and the LSTM network. This will allow us to compare the results and see how well the advanced technique performs.

<div style="text-align:center" id="figure7">
            <img src="/images/exp_setup.png" alt="alt text" width="70%" height="70%"> 
    <br>
    <i>Figure 7: Diagram of the experimental setup</i>
</div>

## Why do we actually need LSTM

When we apply these traditional fitting methods to contaminated probe data, we usually get very poor results. The methods that are applied to the clean probe data are the same applied to the contaminated probe and then fitting parameters are iteratively added to try and recover the correct result. Essentially, we 'remember' the clean probe data and use traditional fitting to get our $n_e$ and $T_e$ and then (under the same plasma conditions) try to make the contaminated probe data fit the same $n_e$ and $T_e$ by tweaking the math we saw in section: [The Langmuir probe and how it works](#Langmuir_math). Additionally we don't actually know by how much the probe is contaminated, so each measurement need to be treated separately to try and calculate a meaningful result.

The LSTM network does exactly the same thing: by remembering the result of the clean probe in the same measurement, it is able to find the relation between the contaminated probe data and the clean probe data, thus predicting the temperature, $T_e$ and density, $n_e$. As the network can learn what a clean vs.contaminated probe's I-V characteristic looks like, when they gave it a new contaminated probe's data, it related it to a clean probes data under the same conditions and give out more accurate $n_e$ and $T_e$ predictions. This gives a more general model and each fit is done automatically rather than manually. 

## Network structure

Now we move onto how the network in this paper is trained and how they went about making sure the LSTM model was best fit to the data. Using two blocks of the LSTM cells from section [LSTM, what is it and how does it work?](#LSTM_cell), a two layer LSTM model is built. However, using a two-layer LSTM network can sometimes cause something called "overfitting," which means the model is too complex for the data it's working with. It picks up on small data patterns such as noise rather than the overall shape of the data (which is what we know is used to calculate the $T_e$ and $n_e$). To avoid this, we're adding something called a "random deactivation layer" after each layer of the LSTM network.

A random deactivation layer helps to prevent overfitting in the LSTM network by randomly deactivating or 'dropping out' some of the neurons during training. This serves to reduce the complexity of the network and make it less likely to memorize the training data and the small details that the network could pick up on as patterns. 

The idea behind dropout is that it prevents neurons from co-adapting too much. In other words, it helps to break the inter-dependency among neurons, which makes the model less sensitive to the specific weights of neurons. By randomly dropping out neurons during training, we force the network to find different ways to solve the problem, look for more general correlations in the data, and increase robustness, which helps to reduce overfitting. This results in a more generalizable model, which is better able to generalize to unseen data.

Finally, they added something called a "fully connected layer" to the network, which will help the network output values that match up with the actual data. They compared the output values of the network to the actual data, and use a specific algorithm called "Adam optimizer" to update and improve the model's parameters.

To summarise, they used an this model structure seen [below](#figure8) to try to find the best way to improve the model without overfitting the data.

<div style="text-align:center" id="figure8">
            <img src="/images/LSTM_full_network.png" alt="alt text" width="80%" height="50%"> 
    <br>
    <i>Figure 8: Diagram of the network setup</i>
</div>

# Results 
## Data
After processing all the data using traditional methods, they obtained a dataset of [5186](#figure8) groups. $n_e$ ranges from 1012 to 1014 $𝑚^{−3}$, $T_e$ ranges from 19,000 to 60,000 K and current ranges 70 A, 80 A, and 85 A. Changing the current to lower values, decreases the density of the plasma. So, they created a large data set in a broad parameter space.

<div style="text-align:center" id="figure9">
            <img src="/images/data.png" alt="alt text" width="80%" height="90%"> 
    <br>
    <i>Figure 9: All data obtained using traditional processing methods</i>
</div>

This data set was split into 4150 training sets and 1036 test sets. 

## Optimising hyperparameters  

When working with a neural network, there are many different parameters you can adjust to improve the performance of the model. These can include things like the number of neurons in each layer, the number of layers, the learning rate and so on... In most cases with neural networks, this training is mostly a trial and error as he process of finding the optimal hyperparameters for a neural network can be challenging as it depends on the complexity of the problem, the size of the dataset, and the architecture of the network. In this specific case, by adjusting these parameters, they were able to fine-tune the model to give the best possible predictions. The researchers are using the accuracy of the prediction of $n_e$ to adjust these parameters and find the best structure for their neural network.

### Evaluation indicators
When it comes to training a machine learning model, it's important to have a way to measure how well the model is performing. This is where evaluation indicators come in. Evaluation indicators are metrics used to measure the performance of a model, and they can help you understand how well the model is making predictions.

In this specific case, the researchers are using two different evaluation indicators: the mean square error (MSE) loss function and the mean absolute percentage error (MAPE).

The MSE loss function is a common metric used in multi-output regression prediction models. It calculates the difference between the predicted value and the actual value, and it's usually used to measure the accuracy of the model during training. It's sensitive to large differences between the predicted and actual values hence, during training the model will change its parameters more if the MSE is large.

After the model has been trained, the researchers are using the MAPE metric to evaluate the performance of the model. The MAPE calculates the percentage difference between the predicted value and the actual value. A percentage error helps to give a more intuitive understanding of how well the model is performing.

### Neuron density
The number of neurons in a layer can drastically change how your network learns. Too may neurons and we may over-fit the data and too few and the neural network may not pick up on the patterns in the data. The researchers varied the number of neurons tested for the networks predictive accuracy. Among them, the network with the 50R4/4/1 structure can achieve a higher accuracy faster. This can be seen [below](#figure10) where the 50R4/4/1 clearly peaks in accuracy well before the other network structures. 

<div style="text-align:center" id="figure10">
            <img src="/images/accuracy_epoch.png" alt="alt text" width="90%" height="90%"> 
    <br>
    <i>Figure 10: Different model structures tested for prediction accuracy of $n_e$. </i>
</div>

50R4/4/1 in the researchers notes means: 50 $\times$ 4 = 200 neurons in the first layer, 50 $\times$ 4 = 200 neurons in the second layer, and 50 $\times$ 1 = 50 neurons in the Full connection layer.

### Learning rate

When it comes to training a neural network, one of the most important things to consider is the learning rate. The learning rate is a hyperparameter that controls the step size at which the optimizer makes updates to the model's weights during training. In other words, it determines how fast the model learns. Imagine you're on a hill and you want to find the best path to take to reach the bottom. If you take too large steps you may miss detail along the way, if you take too small steps, it may take too long to reach the bottom. This works the same way for the optimiser. A high learning rate means that the optimizer is making big jumps in the weight space and can cause the model to converge too quickly to a suboptimal solution or diverge. On the other hand, a low learning rate means that the optimizer is making small steps and can cause the model to converge too slowly to the optimal solution. Finding the sweet spot between these two extremes is crucial to making sure the model is learning efficiently and effectively. In this case, the researchers used various fixed learning rates to see which worked best, of which 0.00001 was the best with lowest RMSE and MAPE. 


<div style="text-align:center" id="figure11">
            <img src="/images/learning_rate.png" alt="alt text" width="100%" height="100%"> 
    <br>
    <i>Figure 11: Testing for different learning rates. </i>
</div>

## Loss and Accuracy

The loss and accuracy lots for both $n_e$ and $T_e$ seen below in [fig. 12](#figure12) show that the researchers were able to achieve a 95% accuracy within just 50 epochs. 
<div style="text-align:center" id="figure12">
            <img src="/images/loss_ne_te.png" alt="alt text" width="100%" height="100%"> 
    <br>
    <i>Figure 12: Looking at the loss and accuracy of predicting $n_e$ and $T_e$. </i>
</div>
They state that they optimised the network hyperparameter structure from just the accuracy of the prediction of $n_e$. I question their choice of method here. Although they are training the model based on the accurate prediction of more than one variable, optimising the structure based on one makes it seem like they're leaving the prediction of $T_e$ down to a lucky guess, rather than a network that models the whole system. Although you can see a relatively high prediction for both $n_e$ and $T_e$, the prediction accuracy for $T_e$ is a few percent lower and the loss function does not converge as well as for $n_e$.

The researchers suggest that the benefit of using an LSTM network for plasma diagnosis lies in the lack of coupling between the acquisition of Ne and Te. This eliminates the potential impact of significant errors in Te on the result of Ne, which is a common issue in traditional diagnostic methods. I would disagree with this statement. With a network structure optimised to predict only only one of the two variables better, the network may be using the prediction of $n_e$ to influence its prediction of $T_e$ hence their prediction may not necessarily be completely decoupled. 

## Prediction 

Using the now trained and tested LSTM network the researchers predict $n_e$ and $T_e$ from contaminated probe data and see if they can eliminate the effect contamination from plasma diagnosis data. Using the now trained and tested LSTM network the researchers predict $n_e$ and $T_e$ from contaminated probe data and see if they can eliminate the effect contamination from plasma diagnosis data. In [fig. 13](#figure13), we see the comparison of the characteristics calculated using classical methods from the clean probe (Ground Truth) in blue, the contaminated probe in grey, and the LSTM prediction in red. Looking at the trends in the data, the contaminated probe seems to under-predict $n_e$. The LSTM almost finds a middle ground between the clean and contaminated probe data, raising the value to $n_e$ to best patch that of the clean probe. Hence, when we compare the error between classical methods and the LSTM model for finding $n_e$ the error decreases by 1/3! 

<div style="text-align:center" id="figure13">
            <img src="/images/comp_ne_te.png" alt="alt text" width="100%" height="100%"> 
    <br>
    <i>Figure 13: Comparing the clean, contaminated and predicted data from the Langmuir probes for $n_e$ and $T_e$. </i>
</div>

This error decrease is not as large for $T_e$. The error between classical methods on the contaminated probe and the LSTM network does decrease by 1/4, however when we look at the graph for $T_e$ we can see that the LSTM is not exactly finding the right pattern. Opposite to the prediction of $n_e$, the effect of contamination on the classical calculation of $T_e$ results in an overestimation. The LSTM seems to over-predict the $T_e$ value, not quite matching the trend of the clean probe data. I can only assume this is because the hyperparameters of the network were optimised on the prediction accuracy of $n_e$, not $T_e$.

In the case of under-dense plasma, the researchers make the the argument that inaccuracy of traditional methods and the the small amount of data in the low density region resulted in low prediction accuracy of the low density region by the LSTM. This is because the calculation process of $T_e$ requires logarithmic fitting of the electron retardation region of the I-V characteristic curve, which can be difficult to achieve in under-dense plasmas, hence the large amount of noise in the classically calculated $T_e$. The limitation of these traditional methods in turn, makes it difficult to use the data to train and predict from the LSTM network. As seen [below](#figure14), both the prediction of $n_e$ and $T_e$ at low density (70A) is not as accurate as higher density, especially for $T_e$. The low prediction accuracy of $T_e$ could not only be due to inaccurate traditional fitting methods, but also because the network's optimal structure was built to optimise $n_e$ prediction. 


<div style="text-align:center" id="figure14">
            <img src="/images/lowdensity.png" alt="alt text" width="100%" height="100%"> 
    <br>
    <i>Figure 14: Comparing $n_e$ and $T_e$ prediction in low and high density plasmas. </i>
</div>


# Conclusions

In conclusion, the use of an LSTM network proved to be an effective method for eliminating contamination and improving the accuracy of plasma diagnoses. By removing the effect of contamination on the probe data, researchers can receive more reliable results and gain a deeper understanding of the plasma's properties, even when the probe is contaminated. The LSTM method only needed 10% of the data points for accurate LSTM $n_e$ and $T_e$ prediction when compared to traditional methods. This is a huge advantage! Less data means measurements can be made for less time and overall more measurements can be made without compromising on the accuracy of the calculated plasma characteristics. 

When predicting $n_e$ and $T_e$ for under-dense plasmas, the researchers argue that not only are traditional methods inaccurate but also there is a significant lack of data in this region to efficiently train the network. Nevertheless, their model performed well at normal density. 

# Review

Overall, the researchers have created a new way of predicting plasma characteristics accurately and efficiently. However, in my opinion (and theirs too), there are some improvements that could be made to better predict $T_e$. Optimising the hyperparameters of the network based on the accuracy of both $n_e$ and $T_e$ or another metric such as the MAE would be better fit to a multi-continuous-output problem. 

Although the researchers made the argument that using an LSTM network essentially decouples the prediction of $n_e$ and $T_e$, reducing the error usually propagated through the classical fitting model, I would argue that the LSTM network would be able to find this coupling in the pattern of the data and still cause exactly the same problem. As the network is more or less a black box to someone who doesn't have access to the code, I cannot back this argument with data, but neither have the researchers. 

The prediction in under-dense plasma, in my opinion should have been made by a separate model specifically trained for under-dense plasma. The relations between clean and contaminated probe data and under-dense plasma together cover an extremely broad parameter space. Especially in the case of under-dense plasma the probes are more vulnerable to sheath and edge charge effects, which effect the data differently to the contamination problem. In addition, the researchers do not separate the prediction of clean and contaminated probes for under-dense plasma. Here it is difficult to tell weather there is an improvement to the classical model compared to the LSTM model. I would suggest separating the two problems, and use deep neural networks to predict parameters at low density without contamination. Here an LSTM would not be needed but perhaps better model can be found to obtain $n_e$ and $T_e$ under low density conditions. 

Finally, an interesting addition to this study could be to add a prediction of the level of contamination to the network. Contamination effects the shape of the data and that effect could be measured. 

# Acknowledgments

I would just like to say thank you to both Mathias Niepert  and Mario Kalimuthu at the University of Stuttgart for running this seminar on machine learning in the sciences. Their course has been very useful to approach ML in a more practical and enjoyable way. Special thanks to Mario for helping me get set up with Markdown and Git!   

*[LSTM]: Long Short-Term Memory
*[$n_e$]: Plasma Density 
*[$T_e$]: Plasma Temperature 
*[MSE]:  mean square error
*[MAPE]: mean absolute percentage error 
*[NN]: Neural Network 